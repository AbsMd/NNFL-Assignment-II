{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2-8.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQw2Tf86WL7t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "outputId": "f17123d2-0363-40c4-a3f0-d7125a09bb38"
      },
      "source": [
        "#SVM\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "from scipy.io import loadmat\n",
        "from sklearn.model_selection import train_test_split as tts\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import random as rnd\n",
        "\n",
        "\n",
        "mat_contents = loadmat('data5.mat')\n",
        "data = mat_contents['x']\n",
        "np.random.shuffle(data)\n",
        "# normalization\n",
        "def normalize(x):\n",
        "  xmean = np.mean(x, axis=0)\n",
        "  xstd = np.std(x)\n",
        "  ret = (x - xmean)/(xstd)  \n",
        "  return ret\n",
        "\n",
        "N, M = data.shape\n",
        "data = data[:, 1:]\n",
        "np.random.shuffle(data)\n",
        "N, M = data.shape\n",
        "ones = np.ones((N, 1))\n",
        "x = data[:, :M-1]\n",
        "x = normalize(x)\n",
        "X = x\n",
        "X = np.concatenate((ones, X), axis=1)\n",
        "Y = data[:, M-1:]\n",
        "\n",
        "for i in range(N):\n",
        "  if (Y[i][0] == 0):\n",
        "    Y[i][0] = -1\n",
        "\n",
        "train_size = int(0.7*N)\n",
        "validation_size = int(0.1*N)\n",
        "trainX = X[:train_size, :]\n",
        "trainY = Y[:train_size, :]\n",
        "valX = X[train_size:train_size+validation_size, :]\n",
        "valY = Y[train_size:train_size+validation_size, :]\n",
        "testX = X[train_size+validation_size:, :]\n",
        "testY = Y[train_size+validation_size:, :]\n",
        "\n",
        "def kernel(x1, x2, ker):\n",
        "  if ker == 'linear':\n",
        "    return np.dot(x1, x2.T)\n",
        "\n",
        "  elif ker == 'quad':\n",
        "    return np.dot(x1, x2.T)**2\n",
        "\n",
        "  elif ker == 'gauss':\n",
        "    return np.exp(- (np.linalg.norm(x1 - x2, 2)) ** 2 / (2))\n",
        "\n",
        "def calc_w(x, y, alpha):\n",
        "  return np.dot(x.T, np.multiply(alpha, y))\n",
        "\n",
        "def calc_b(x, y, w):\n",
        "  return np.mean(y - np.dot(w.T, x.T))\n",
        "\n",
        "def compute_L_H(C, al_j, al_i, y_j, y_i):\n",
        "  if (y_i != y_j):\n",
        "      return (max(0, al_j - al_i), min(C, C - al_i + al_j))\n",
        "  else:\n",
        "      return (max(0, al_i + al_j - C), min(C, al_i + al_j))\n",
        "\n",
        "def rand_int(a, b, z):\n",
        "  i = z\n",
        "  count = 0\n",
        "  while i == z and count < 1000:\n",
        "      i = rnd.randint(a,b)\n",
        "      count = count+1\n",
        "  return i\n",
        "\n",
        "def h(X, w, b):\n",
        "  return np.sign(np.dot(w.T, X.T) + b).astype(int)\n",
        "\n",
        "def E(x_k, y_k, w, b):\n",
        "  return h(x_k, w, b) - y_k\n",
        "\n",
        "def predict(w, X, b):\n",
        "  return h(X, w, b)\n",
        "\n",
        "\n",
        "\n",
        "def SVM(x, y, ker, epsilon, max_iter, C):\n",
        "  n, m = x.shape\n",
        "  alpha = np.zeros((n, 1))\n",
        "  count = 0\n",
        "\n",
        "  for i in range(max_iter-1):\n",
        "    count += 1\n",
        "    alpha_prev = np.copy(alpha)\n",
        "    for j in range(n):\n",
        "      i = rand_int(0, n-1, j)\n",
        "      xi, xj, yi, yj = x[i, :], x[j, :], y[i][0], y[j][0]\n",
        "      kij = kernel(xi, xi, ker) + kernel(xj, xj, ker) - 2*kernel(xi, xj, ker)\n",
        "      if kij == 0:\n",
        "        continue\n",
        "\n",
        "      al_i, al_j = alpha[i], alpha[j]\n",
        "      (L, H) = compute_L_H(C, al_j, al_i, yj, yi)\n",
        "      w = calc_w(x, y, alpha)\n",
        "      b = calc_b(x, y, w)\n",
        "\n",
        "      E_i = E(xi, yi, w, b)\n",
        "      E_j = E(xj, yj, w, b)\n",
        "      alpha[j] = al_j + float(yj * (E_i - E_j)) / kij\n",
        "      alpha[j] = max(alpha[j], L)\n",
        "      alpha[j] = min(alpha[j], H)\n",
        "      alpha[i] = al_i + yi*yj * (al_j - alpha[j])\n",
        "    diff = np.linalg.norm(alpha - alpha_prev)\n",
        "    if diff < epsilon:\n",
        "        break\n",
        "\n",
        "  b = calc_b(x, y, w)\n",
        "  if ker == 'linear':\n",
        "      w = calc_w(x, y, alpha)\n",
        "  alpha_idx = np.where(alpha > 0)[0]\n",
        "  support_vectors = x[alpha_idx, :]\n",
        "  return support_vectors, count, w, b\n",
        "\n",
        "support_vec, count, w, b = SVM(trainX, trainY, 'gauss', 0.1, 10, 1)\n",
        "pred_y = predict(w, testX, b)\n",
        "n, m = testY.shape\n",
        "tp, tn, fp, fn = 0,0,0,0\n",
        "for i in range(n):\n",
        "  if (trainY[i][0] == 1.0) & (pred_y[0][i] == 1.0):\n",
        "      tp += 1\n",
        "  elif (trainY[i][0] == 1.0) & (pred_y[0][i] == 0.0):\n",
        "      fn += 1\n",
        "  elif (trainY[i][0] == 0.0) & (pred_y[0][i] == 1.0):\n",
        "      fp +=1\n",
        "  elif (trainY[i][0] == 0.0) & (pred_y[0][i] == 0.0):\n",
        "      tn += 1\n",
        "\n",
        "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
        "sensitivity = tp / (tp + fn)\n",
        "specificity = tn / (tn + fp)\n",
        "\n",
        "print('Accuracy: ',accuracy,'sensitivity: ', sensitivity,'specificity: ', specificity)\n",
        "  "
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ZeroDivisionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-9d6024d1dbea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtp\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtp\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtn\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfp\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0msensitivity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtp\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtp\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m \u001b[0mspecificity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtn\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtn\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy: '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'sensitivity: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msensitivity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'specificity: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspecificity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6P2UdUPnu5i",
        "outputId": "cf2ecd97-fc1a-4ed1-b8d8-304caf54b7e2"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.io import loadmat\n",
        "import scipy.io\n",
        "from sklearn.preprocessing import normalize\n",
        "import random as rnd\n",
        "from __future__ import division, print_function\n",
        "from sklearn.metrics import confusion_matrix as cm\n",
        "\n",
        "mat = scipy.io.loadmat('data5.mat')\n",
        "data = mat['x']\n",
        "data = np.asarray(data)\n",
        "np.random.shuffle(data)\n",
        "len = data.shape[0]\n",
        "\n",
        "train = int(0.7 * len)\n",
        "val = int((0.1 * len) + 1)\n",
        "test = int((0.2 * len) + 1)\n",
        "train_data = data[0 : train,:]\n",
        "val_data = data[train+1 : train+1+val,:]\n",
        "test_data = data[train+val+1 :,:]\n",
        "\n",
        "x_train = train_data[:,0:72]\n",
        "y_train = train_data[:,-1]\n",
        "x_val = val_data[:,0:72]\n",
        "y_val = val_data[:,-1]\n",
        "x_test = test_data[:,0:72]\n",
        "y_test = test_data[:,-1]\n",
        "\n",
        "for i in range(y_train.shape[0]):\n",
        "  y_train[i] = int(y_train[i])\n",
        "  if int(y_train[i]) == 0:\n",
        "    y_train[i] = -1\n",
        "for i in range(y_val.shape[0]):\n",
        "  y_val[i] = int(y_val[i])\n",
        "  if int(y_val[i]) == 0:\n",
        "    y_val[i] = -1\n",
        "for i in range(y_test.shape[0]):\n",
        "  y_test[i] = int(y_test[i])\n",
        "  if int(y_test[i]) == 0:\n",
        "    y_test[i] = -1\n",
        "\n",
        "class SVM():\n",
        "    def __init__(self, max_iter=5000, kernel_type='linear', C=1.0, epsilon=0.001):\n",
        "        self.kernels = {\n",
        "            'linear' : self.kernel_linear,\n",
        "            'quadratic' : self.kernel_quadratic\n",
        "        }\n",
        "        self.max_iter = max_iter\n",
        "        self.kernel_type = kernel_type\n",
        "        self.C = C\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        n, d = X.shape[0], X.shape[1]\n",
        "        alpha = np.zeros((n))\n",
        "        kernel = self.kernels[self.kernel_type]\n",
        "        count = 0\n",
        "        while True:\n",
        "            count += 1\n",
        "            alpha_prev = np.copy(alpha)\n",
        "            for j in range(0, n):\n",
        "                i = self.get_rnd_int(0, n-1, j) \n",
        "                x_i, x_j, y_i, y_j = X[i,:], X[j,:], y[i], y[j]\n",
        "                k_ij = kernel(x_i, x_i) + kernel(x_j, x_j) - 2 * kernel(x_i, x_j)\n",
        "                if k_ij == 0:\n",
        "                    continue\n",
        "                alpha_prime_j, alpha_prime_i = alpha[j], alpha[i]\n",
        "                (L, H) = self.compute_L_H(self.C, alpha_prime_j, alpha_prime_i, y_j, y_i)\n",
        "\n",
        "                self.w = self.calc_w(alpha, y, X)\n",
        "                self.b = self.calc_b(X, y, self.w)\n",
        "\n",
        "                E_i = self.E(x_i, y_i, self.w, self.b)\n",
        "                E_j = self.E(x_j, y_j, self.w, self.b)\n",
        "\n",
        "                alpha[j] = alpha_prime_j + float(y_j * (E_i - E_j))/k_ij\n",
        "                alpha[j] = max(alpha[j], L)\n",
        "                alpha[j] = min(alpha[j], H)\n",
        "\n",
        "                alpha[i] = alpha_prime_i + y_i*y_j * (alpha_prime_j - alpha[j])\n",
        "\n",
        "            diff = np.linalg.norm(alpha - alpha_prev)\n",
        "            if diff < self.epsilon:\n",
        "                break\n",
        "\n",
        "            if count >= self.max_iter:\n",
        "                return\n",
        "\n",
        "        self.b = self.calc_b(X, y, self.w)\n",
        "        if self.kernel_type == 'linear':\n",
        "            self.w = self.calc_w(alpha, y, X)\n",
        "\n",
        "        alpha_ind = np.where(alpha > 0)[0]\n",
        "        support_vectors = X[alpha_ind, :]\n",
        "        return support_vectors, count\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self.h(X, self.w, self.b)\n",
        "\n",
        "    def calc_b(self, X, y, w):\n",
        "        b_tmp = y - np.dot(w.T, X.T)\n",
        "        return np.mean(b_tmp)\n",
        "\n",
        "    def calc_w(self, alpha, y, X):\n",
        "        return np.dot(X.T, np.multiply(alpha,y))\n",
        "\n",
        "    def h(self, X, w, b):\n",
        "        return np.sign(np.dot(w.T, X.T) + b).astype(int)\n",
        "\n",
        "    def E(self, x_k, y_k, w, b):\n",
        "        return self.h(x_k, w, b) - y_k\n",
        "\n",
        "    def compute_L_H(self, C, alpha_prime_j, alpha_prime_i, yj, yi):\n",
        "        if(yi != yj):\n",
        "            return (max(0, alpha_prime_j - alpha_prime_i), min(C, C - alpha_prime_i + alpha_prime_j))\n",
        "        else:\n",
        "            return (max(0, alpha_prime_i + alpha_prime_j - C), min(C, alpha_prime_i + alpha_prime_j))\n",
        "\n",
        "    def get_rnd_int(self, a,b,z):\n",
        "        i = z\n",
        "        count=0\n",
        "        while i == z and count<1000:\n",
        "            i = rnd.randint(a,b)\n",
        "            count += 1\n",
        "        return i\n",
        "\n",
        "    def kernel_linear(self, x1, x2):\n",
        "        return np.dot(x1, x2.T)\n",
        "\n",
        "    def kernel_quadratic(self, x1, x2):\n",
        "        return (np.dot(x1, x2.T) ** 2)\n",
        "\n",
        "def print_acc(y_pred,y_actual):\n",
        "    confmat = cm(y_actual, y_pred)\n",
        "    Accuracy = (confmat[0][0]+confmat[1][1])/ (np.shape(y_pred)[0])\n",
        "    Sensitivity = (confmat[1][1])/(confmat[1][0] + confmat[1][1])\n",
        "    Specificity = (confmat[0][0])/(confmat[0][0] + confmat[0][1])\n",
        "    \n",
        "    print(confmat)\n",
        "    print(\"\\n\")\n",
        "    print(f\"Accuracy: {Accuracy*100}%\\nSensitivity: {Sensitivity}\\nSpecificity: {Specificity}\\n\")\n",
        "\n",
        "svm = SVM()\n",
        "svm.fit(x_train,y_train)\n",
        "y_pred = svm.predict(x_test)\n",
        "\n",
        "print_acc(y_pred,y_test)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[163  53]\n",
            " [ 23 190]]\n",
            "\n",
            "\n",
            "Accuracy: 82.28438228438229%\n",
            "Sensitivity: 0.892018779342723\n",
            "Specificity: 0.7546296296296297\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}