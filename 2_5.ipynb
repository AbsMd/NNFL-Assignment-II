{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2-5.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmwYh3cS16VB",
        "outputId": "05d843cd-89a5-448b-e51d-8726a116d4a4"
      },
      "source": [
        "#stacked autoencoder based deep neural network for classification\n",
        "import numpy as np\n",
        "from scipy.io import loadmat\n",
        "\n",
        "#Load data, shuffle and normalize\n",
        "mat_contents = loadmat('data5.mat')\n",
        "data = mat_contents['x']\n",
        "np.random.shuffle(data)\n",
        "\n",
        "\n",
        "def init_data():\n",
        "    X = np.array(data[ : , :-1], dtype = float)\n",
        "    y = np.array(data[ : , -1], dtype = int)\n",
        "    X = (X - X.mean(axis = 0))/X.std(axis = 0)\n",
        "    return X, y\n",
        "\n",
        "X, y = init_data()\n",
        "\n",
        "#Hold out\n",
        "X_train, y_train = X[ :int(0.7 * len(X))], y[ :int(0.7 * len(X))]\n",
        "X_val, y_val = X[ int(0.7 * len(X)): ], y[ int(0.7 * len(X)): ]\n",
        "\n",
        "alpha = 0.5\n",
        "\n",
        "#Sigmoid activation function\n",
        "def sigmoid(x, derivative=False):\n",
        "        if (derivative == True):\n",
        "            return x * (1 - x)\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "class NeuralNetwork(object):\n",
        "    def __init__(self, sizes):\n",
        "        \n",
        "        self.num_layers = len(sizes)\n",
        "        self.sizes = sizes\n",
        "        self.W = {}\n",
        "        self.a = {}\n",
        "        self.b = {}\n",
        "        \n",
        "        #Initialize Weights\n",
        "        for i in range(1, self.num_layers):\n",
        "            self.W[i] = np.random.randn(self.sizes[i-1], self.sizes[i])\n",
        "            \n",
        "        #Initialize biases\n",
        "        for i in range(1, self.num_layers):\n",
        "            self.b[i] = np.random.randn(self.sizes[i], 1)\n",
        "        \n",
        "        #Initialize activations\n",
        "        for i in range(1, self.num_layers):\n",
        "            self.a[i] = np.zeros([self.sizes[i], 1])\n",
        "        \n",
        "    #Forward pass to compute scores\n",
        "    def forward_pass(self, X):\n",
        "        \n",
        "        self.a[0] = X\n",
        "        \n",
        "        for i in range(1, self.num_layers):\n",
        "            self.a[i] = sigmoid(np.dot(self.W[i].T, self.a[i-1]) + self.b[i])\n",
        "\n",
        "        return self.a[self.num_layers-1] \n",
        "    \n",
        "    #Backward pass to update weights\n",
        "    def backward_pass(self, X, Y, output):\n",
        "        \n",
        "        self.d = {}\n",
        "        self.d_output = (Y - output) * sigmoid(output, derivative=True)\n",
        "        self.d[self.num_layers-1] = self.d_output\n",
        "        \n",
        "        #Derivatives of the layers wrt loss\n",
        "        for i in range(self.num_layers-1, 1, -1):\n",
        "            self.d[i-1] = np.dot(self.W[i], self.d[i]) * sigmoid(self.a[i-1], derivative=True)\n",
        "        \n",
        "        #Updating weights\n",
        "        for i in range(1, self.num_layers-1):\n",
        "            self.W[i] += alpha * np.dot(self.a[i-1], self.d[i].T)\n",
        "            \n",
        "        #Updating biases\n",
        "        for i in range(1, self.num_layers-1):\n",
        "            self.b[i] += alpha * self.d[i]\n",
        "\n",
        "    #Training helper function   \n",
        "    def train(self, X, Y):\n",
        "        X = np.reshape(X, (len(X), 1))\n",
        "        output = self.forward_pass(X)\n",
        "        self.backward_pass(X, Y, output)\n",
        "\n",
        "    #Get weights    \n",
        "    def get_W(self):\n",
        "        return self.W\n",
        "    \n",
        "    #Load specified weights\n",
        "    def load_W(self, W):\n",
        "        self.W = W\n",
        "\n",
        "    #Scores computation for given input    \n",
        "    def get_a(self, x):\n",
        "        x = np.reshape(x, (len(x), 1))\n",
        "        self.forward_pass(x)\n",
        "        return self.a\n",
        "    \n",
        "    #Helper function for autoencoder chaining\n",
        "    def load_a(self, a):\n",
        "        self.a = a\n",
        "\n",
        "    \n",
        "\n",
        "#cost function\n",
        "def calc_cost(NN,x ,y):\n",
        "    \n",
        "    cost = 0\n",
        "    for i in range(len(x)):\n",
        "        x_ = np.reshape(x[i], (len(x[i]), 1))\n",
        "        cost += 0.5 / len(x) * np.sum((y[i] - NN.forward_pass(x_)) ** 2)\n",
        "    \n",
        "    return cost\n",
        "\n",
        "#Network initialization\n",
        "autoencoder1 = NeuralNetwork([72, 60, 72])\n",
        "autoencoder2 = NeuralNetwork([60,40,60])\n",
        "autoencoder3 = NeuralNetwork([40, 30, 40])\n",
        "NN = NeuralNetwork([72,60,40,30, 1])\n",
        "\n",
        "#AE 1 pretraining\n",
        "for i in range(200):\n",
        "    for j, row in enumerate(X_train):\n",
        "        row = np.reshape(row, (72,1))\n",
        "        autoencoder1.train(row, row)\n",
        "        \n",
        "    cost = calc_cost(autoencoder1, X_train, X_train)\n",
        "    if i%50 ==0:\n",
        "      print(\"Epoch {}, cost {}\".format(i, cost))\n",
        "    \n",
        "#Scores for AE 1\n",
        "autoencoder2_input = []\n",
        "\n",
        "for row in X_train:\n",
        "    autoencoder2_input.append(autoencoder1.get_a(row)[1])\n",
        "\n",
        "autoencoder2_input = np.array(autoencoder2_input)\n",
        "\n",
        "\n",
        "#AE 2 pretraining\n",
        "for i in range(200):\n",
        "    for j, row in enumerate(autoencoder2_input):\n",
        "        row = np.reshape(row, (60,1))\n",
        "        autoencoder2.train(row, row)\n",
        "        \n",
        "    cost = calc_cost(autoencoder2, autoencoder2_input, autoencoder2_input)\n",
        "    if i%50 ==0:\n",
        "      print(\"Epoch {}, cost {}\".format(i, cost))\n",
        "\n",
        "\n",
        "#Scores for AE 2\n",
        "autoencoder3_input = []\n",
        "\n",
        "for row in autoencoder2_input:\n",
        "    autoencoder3_input.append(autoencoder2.get_a(row)[1])\n",
        "\n",
        "autoencoder3_input = np.array(autoencoder3_input)\n",
        "\n",
        "#AE 3 pretraining\n",
        "for i in range(200):\n",
        "    for j, row in enumerate(autoencoder3_input):\n",
        "        row = np.reshape(row, (40,1))\n",
        "        autoencoder3.train(row, row)\n",
        "        \n",
        "    cost = calc_cost(autoencoder3, autoencoder3_input, autoencoder3_input)\n",
        "    if i%50 ==0:\n",
        "      print(\"Epoch {}, cost {}\".format(i, cost))\n",
        "\n",
        "#Final network weight initialization\n",
        "W1 = autoencoder1.get_W()[1]\n",
        "W2 = autoencoder2.get_W()[1]\n",
        "W3 = autoencoder3.get_W()[1]\n",
        "W_final = {}\n",
        "W_final[1] = W1\n",
        "W_final[2] = W2\n",
        "W_final[3] = W3\n",
        "W_final[4] = np.random.randn(30, 1)\n",
        "NN.load_W(W_final)\n",
        "\n",
        "#Training loop\n",
        "for i in range(500):\n",
        "\n",
        "    for j in range(len(X_train)):\n",
        "        NN.train(X_train[j], y_train[j])\n",
        "\n",
        "tp, tn, fp, fn = 0,0,0,0\n",
        "\n",
        "for i in range(len(X_val)):\n",
        "\n",
        "    x = np.reshape(X_val[i], (len(X_val[i]), 1))\n",
        "    x = NN.forward_pass(x)\n",
        "    p = 0 if x[0] < 0.5 else 1\n",
        "\n",
        "    if p == 1 and y_val[i] == 1:\n",
        "        tp += 1\n",
        "    elif p == 0 and y_val[i] == 0:\n",
        "        tn += 1\n",
        "    elif p == 1 and y_val[i] == 0:\n",
        "        fp += 1\n",
        "    elif p == 0 and y_val[i] == 1:\n",
        "        fn += 1\n",
        "\n",
        "print(tp, fp)\n",
        "print(fn, tn)\n",
        "\n",
        "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
        "sensitivity = tp / (tp + fn)\n",
        "specificity = tn / (tn + fp)\n",
        "\n",
        "print(\"accuracy = \", accuracy, \"sensitivity = \", sensitivity, \"specificity = \", specificity)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: RuntimeWarning: overflow encountered in exp\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0, cost 2985.0438692089747\n",
            "Epoch 50, cost 2859.8079107687013\n",
            "Epoch 100, cost 2863.3191282112566\n",
            "Epoch 150, cost 2861.8041797859546\n",
            "Epoch 0, cost 6.010090907942298\n",
            "Epoch 50, cost 5.186879801320856\n",
            "Epoch 100, cost 5.207901210815339\n",
            "Epoch 150, cost 5.2068806593264565\n",
            "Epoch 0, cost 2.811563101475409\n",
            "Epoch 50, cost 2.5031379207394813\n",
            "Epoch 100, cost 2.5025840233315195\n",
            "Epoch 150, cost 2.497614544169333\n",
            "282 25\n",
            "28 310\n",
            "accuracy =  0.9178294573643411 sensitivity =  0.9096774193548387 specificity =  0.9253731343283582\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}