{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2-1.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOw0bb3NwcdG7BfvsX4nf+2"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JX7zZCJG-IWk","executionInfo":{"status":"ok","timestamp":1606531509293,"user_tz":-330,"elapsed":1591,"user":{"displayName":"M ABHINAVA","photoUrl":"","userId":"12313623155509412289"}},"outputId":"924bb733-5f0a-4e92-e1a6-ca57a68d9076"},"source":["import math \n","import numpy as np\n","import pandas as pd\n","\n","def get_column(data,c):\n","    column = []\n","    for i in range(len(data)):\n","        column.append(data[i][c])\n","    return column\n","\n","def set(y):\n","    for i in range(len(y)):\n","        if (y[i]>=0.5):\n","            y[i] = 1\n","        if (y[i]<0.5):\n","            y[i] = 0\n","    return y\n","\n","def sigmoid(x):\n","    return 1 / (1 + math.exp(-x))\n","\n","def nlp(x_tr, y_tr, iterations, alpha):\n","    m = x_tr.shape[0]\n","    a = np.random.normal(0, 1, size=(5))\n","    w1 = a[0]\n","    w2 = a[1]\n","    w3 = a[2]\n","    w4 = a[3]\n","    b = a[4]\n","    hyp = 0\n","    for iter in range(iterations):\n","      for i in range(m):\n","        hyp += (w1*x_tr[i,0]) + (w2*x_tr[i,1]) + (w3*x_tr[i,2]) + (w4*x_tr[i,3]) + b\n","        hyp = sigmoid(hyp)\n","        if (hyp >= 0.5):\n","          hyp = 1\n","        else:\n","          hyp = 0\n","        if (hyp != y_tr[i]):\n","          w1 += (alpha * y_tr[i] * x_tr[i,0])\n","          w2 += (alpha * y_tr[i] * x_tr[i,1])\n","          w3 += (alpha * y_tr[i] * x_tr[i,2])\n","          w4 += (alpha * y_tr[i] * x_tr[i,3])\n","          b += (alpha * y_tr[i])\n","    return w1, w2, w3, w4, b\n","\n","#Normalization\n","def normalize(data):\n","    normalized_data = data\n","    for i in range(5):\n","        maxval = max(get_column(data,i))\n","        minval = min(get_column(data,i))\n","        for j in range(len(data)):\n","            normalized_data[j][i] = (data[j][i]-minval)/(maxval-minval)\n","    return normalized_data\n","\n","#Data\n","data = pd.read_excel('data55.xlsx',header=None)\n","data = data.sample(frac=1).reset_index(drop=True)\n","#print(data)\n","#print(type(data))\n","data = data.to_numpy()\n","print(data.shape)\n","y = data[:,-1]\n","data = normalize(data)\n","x = data[:,:-1]\n","\n","iterations = 1000\n","alpha = 0.01\n","\n","#Split into testing and training sets\n","train_size = int(0.7 * len(x))\n","val_limit = int(0.8*len(x))\n","x_tr = x[:train_size]\n","x_val = x[train_size:val_limit]\n","x_ts = x[val_limit:]\n","y_tr = y[:train_size]\n","y_val = y[train_size:val_limit]\n","y_ts = y[val_limit:]\n","\n","w1,w2,w3,w4, b = nlp(x_tr,y_tr, iterations, alpha)\n","print(w1,w2,w3,w4)\n","\n","x = x_val\n","yp = [0 for i in range(len(x))]\n","for i in range(len(x)):\n","    yp[i] = (w1*x[i,0]) + (w2*x[i,1]) + (w3*x[i,2]) + (w4*x[i,3]) + b\n","    yp[i] = sigmoid(yp[i])\n","y_val = set(y_val)\n","yp = set(yp)\n","print(yp)\n","y_actual = pd.Series(y_val, name='Actual')\n","y_pred = pd.Series(yp, name='Predicted')\n","confmat = pd.crosstab(y_actual, y_pred)\n","print(confmat)\n","confmat = np.asarray(confmat)\n","tp1 = confmat[1][1]\n","tn1 = confmat[0][0]\n","fp1 = confmat[0][1]\n","fn1 = confmat[1][0]\n","\n","validation_accuracy = (tp1+tn1)/(tp1+tn1+fp1+fn1)\n","print('Validation Accuracy : ' + str(validation_accuracy) + '\\n')\n","\n","x = x_ts\n","yp = [0 for i in range(len(x))]\n","for i in range(len(x)):\n","    yp[i] = (w1*x[i,0]) + (w2*x[i,1]) + (w3*x[i,2]) + (w4*x[i,3]) + b\n","    yp[i] = sigmoid(yp[i])\n","y_ts = set(y_ts)\n","yp = set(yp)\n","print(yp)\n","y_actual = pd.Series(y_ts, name='Actual')\n","y_pred = pd.Series(yp, name='Predicted')\n","confmat = pd.crosstab(y_actual, y_pred)\n","print(confmat)\n","confmat = np.asarray(confmat)\n","tp = confmat[1][1]\n","tn = confmat[0][0]\n","fp = confmat[0][1]\n","fn = confmat[1][0]\n","\n","test_accuracy = (tp+tn)/(tp+tn+fp+fn)\n","sensitivity = tp/(tp+fn)\n","specificity = tn/(tn+fp)\n","\n","print('\\nTest Accuracy : ' + str(test_accuracy))\n","print('sensitivity : ' + str(sensitivity))\n","print('specificity : ' + str(specificity))\n","\n","\n","#Since there are only 100 instances(10 instances for val and 20 for test) \n","#and data.sample sometimes doesn't shuffle the data properly,\n","#it is possible to get an error in confmat index, please run till the shuffling is acceptable"],"execution_count":2,"outputs":[{"output_type":"stream","text":["(100, 5)\n","1.1238075613816427 -1.9073457989392595 -0.6912392335192649 1.3406880806726353\n","[0, 1, 0, 0, 1, 0, 1, 0, 0, 0]\n","Predicted  0  1\n","Actual         \n","0.0        7  0\n","1.0        0  3\n","Validation Accuracy : 1.0\n","\n","[0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0]\n","Predicted  0   1\n","Actual          \n","0.0        9   0\n","1.0        1  10\n","\n","Test Accuracy : 0.95\n","sensitivity : 0.9090909090909091\n","specificity : 1.0\n"],"name":"stdout"}]}]}